{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1ysMUOdDHnbw5CAGyjUHbnzGoj7fZzLkh",
      "authorship_tag": "ABX9TyPwiy7Kkgq3EbzutQxGlZ/a",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/646e62/legal-informatics/blob/master/canlii_skca_extractor.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# SKCA extractor\n",
        "\n",
        "## HTML to Markdown\n",
        "\n",
        "Although there may be some clues to be found in the way the original CanLII document is structured, it contains an overwhelming amount of data. A lot of that data is unhelpful noise.\n",
        "\n",
        "As it turned out, the HTML to Markdown converter ``html2text`` was able to ignore that noise and pick out multiple key features (document structure, where paragraphs actually start and stop, etc). Should the need for fine tuning arise, there may need to be some HTML pre-processing. But for the time being, the Markdown document is more than sufficient for the program's purpose.\n",
        "\n",
        "## Metadata\n",
        "\n",
        "After creating the Markdown document and splitting it into its natural paragraphs, it became apparent that paragraph[0] contained a fair bit of metadata that could be extracted with some text processing.\n",
        "\n",
        "Although SKCA metadata isn't as extensive or specific as some other jurisdictions, it is informative. Specifically, the fact that SKCA outlines case features like \"disposition\" in easily-located plain text make these documents easy to work with.\n",
        "\n",
        "## Document structure\n",
        "\n",
        "Another thing that became apparent after creating the Markdown document was the fact that ``html2text`` did a good job of capturing document structure.\n",
        "\n",
        "## Text analysis\n",
        "\n",
        "## TODO\n",
        "\n",
        "* Appellate\n",
        "    * Good metadata\n",
        "        * BCCA\n",
        "        * SKCA\n",
        "        * QCCA\n",
        "        * NBCA\n",
        "        * NSCA\n",
        "        * PECA\n",
        "        * YKCA\n",
        "    * Viable metadata\n",
        "        * NLCA\n",
        "    * Inadequate metadata\n",
        "        * ABCA\n",
        "        * MBCA\n",
        "        * ONCA\n",
        "        * NWTCA\n",
        "        * NUCA\n"
      ],
      "metadata": {
        "id": "W_Kahvi0yRFL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Imports and installations\n",
        "\n",
        "### html2text\n",
        "\n",
        "The extractor uses html2text-2020.1.16 to generate Markdown files."
      ],
      "metadata": {
        "id": "Cph3w6TYfSFd"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 115,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GgJ-lRPtHIPZ",
        "outputId": "ce4fba12-6d37-4885-e371-5ca67478c88d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: html2text in /usr/local/lib/python3.10/dist-packages (2020.1.16)\n"
          ]
        }
      ],
      "source": [
        "!pip install html2text"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import html2text\n",
        "import re\n",
        "\n",
        "from typing import Dict, List, Union\n",
        "from datetime import datetime\n"
      ],
      "metadata": {
        "id": "vPUeRY6MewLp"
      },
      "execution_count": 116,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Patterns file\n",
        "\n",
        "This program is designed to work with decisions published on CanLII. Every such decision contains consistent metacontent that the UNWANTED_PATTERNS constant captures via regex.\n",
        "\n",
        "Although I print the Markdown file throughout this working document for troubleshooting purposes, the final version of the program will not print or return the Markdown file to the user.\n",
        "\n",
        "After dealing with the universal metacontent, the program will need to account for the metadata and metadata structures added by the SKCA. Unlike commercial products like WL and QL, CanLII doesn't use a universal format for its decisions. Rather, it appears to allow individual courts to structure their documents as they see fit. Although commendable from a \"marketplace of ideas\" perspective, it makes it more difficult to access metadata and other such content in a consistent way. Rather than developing\n",
        "\n",
        "Data from the SKCA is both immediately important to me and\n",
        "\n",
        "Because SKCA structures its decision metadata in a fairly predictable and regimented way, the same regex-based approach can be used to separate the data from"
      ],
      "metadata": {
        "id": "6OQ_4grgfCt9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "UNWANTED_PATTERNS = [\n",
        "    r'\\[ !\\[CanLII Logo\\]\\(.+?\\) \\]\\(.+?\\)',\n",
        "    r'\\[Home\\]\\(.+?\\) â€º .+?CanLII\\)',\n",
        "    r'Loading paragraph markers __',\n",
        "    r'\\* Document',\n",
        "    r'\\* History  __',\n",
        "    r'\\* Cited documents  __',\n",
        "    r'\\* Treatment  __',\n",
        "    r'\\* CanLII Connects  __',\n",
        "    r'Citations  __',\n",
        "    r'Discussions  __',\n",
        "    r'Unfavourable mentions  __',\n",
        "    r'\\nExpanded Collapsed\\n'\n",
        "]\n",
        "\n",
        "# Metadata patterns for SKCA decisions on CanLII after 2015\n",
        "\n",
        "SKCA_2015_METADATA_PATTERNS = {\n",
        "    'docket': r'Docket:\\s*(.+?)\\s{2,}',\n",
        "    'citation_secondary': r'Citation:\\s*(.+?)\\s{2,}',\n",
        "    'date_secondary': r'Date:\\s*(.+?)\\s{2,}',\n",
        "    'between': r'Between:(.*?)(?=Before:)',\n",
        "    'disposition': r'Disposition:\\s*(.+?)\\s{2,}',\n",
        "    'on_appeal_from': r'On appeal from:\\s*(.+?)\\s{2,}',\n",
        "    'appeal_heard': r'Appeal heard:\\s*(.+?)\\s{2,}',\n",
        "    'application_heard': r'Application heard:\\s*([\\w\\s,]+)'\n",
        "}\n",
        "\n",
        "BASE_ROLES = [\n",
        "    'plaintiff', 'plaintiffs',\n",
        "    'respondent', 'respondents',\n",
        "    'appellant', 'appellants',\n",
        "    'applicant', 'applicants'\n",
        "]\n",
        "\n",
        "# Generate combinations with brackets and slashes\n",
        "ROLES = BASE_ROLES + [\n",
        "    f\"({role})\" for role in BASE_ROLES\n",
        "] + [\n",
        "    f\"{role1}/{role2}\" for role1 in BASE_ROLES for role2 in BASE_ROLES\n",
        "]"
      ],
      "metadata": {
        "id": "DIVEUTE6ewT9"
      },
      "execution_count": 185,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# HTML to MD functions\n",
        "\n"
      ],
      "metadata": {
        "id": "H1UC997rtRjM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def html_to_markdown(html_content: str) -> str:\n",
        "    \"\"\"\n",
        "    Converts HTML content to its markdown representation.\n",
        "\n",
        "    Args:\n",
        "        html_content (str): The input HTML content.\n",
        "\n",
        "    Returns:\n",
        "        str: The converted markdown content.\n",
        "    \"\"\"\n",
        "\n",
        "    h = html2text.HTML2Text()\n",
        "    h.ignore_links = False\n",
        "    return h.handle(html_content)\n",
        "\n",
        "def convert_file(html_filepath: str, markdown_filepath: str) -> None:\n",
        "    \"\"\"\n",
        "    Converts an HTML file to a markdown file.\n",
        "\n",
        "    Args:\n",
        "        html_filepath (str): Path to the input HTML file.\n",
        "        markdown_filepath (str): Path to the output markdown file.\n",
        "    \"\"\"\n",
        "\n",
        "    with open(html_filepath, 'r', encoding='utf-8') as file:\n",
        "        html_content = file.read()\n",
        "\n",
        "    markdown_content = html_to_markdown(html_content)\n",
        "    refined_markdown_content = refine_markdown(markdown_content)\n",
        "\n",
        "    with open(markdown_filepath, 'w', encoding='utf-8') as file:\n",
        "        file.write(refined_markdown_content)\n",
        "\n",
        "def refine_markdown(md_content: str, unwanted_patterns: List[str] = UNWANTED_PATTERNS) -> str:\n",
        "    \"\"\"\n",
        "    Refines the markdown content by making specific replacements and deletions.\n",
        "\n",
        "    Args:\n",
        "        md_content (str): The input markdown content.\n",
        "        unwanted_patterns (List[str], optional): List of regex patterns to be removed from the content. Defaults to UNWANTED_PATTERNS.\n",
        "\n",
        "    Returns:\n",
        "        str: The refined markdown content.\n",
        "    \"\"\"\n",
        "\n",
        "    # Replace only the first occurrence of '## ' with '# '\n",
        "    md_content = md_content.replace('## ', '# ', 1)\n",
        "\n",
        "    # Remove hard line breaks after labels\n",
        "    md_content = re.sub(r'Date:\\s*\\n', 'Date: ', md_content)\n",
        "    md_content = re.sub(r'File number:\\s*\\n', 'File number: ', md_content)\n",
        "    md_content = re.sub(r'Citation:\\s*\\n', 'Citation: ', md_content)\n",
        "\n",
        "    # Remove unwanted sections from the captured content\n",
        "    for pattern in unwanted_patterns:\n",
        "        md_content = re.sub(pattern, '', md_content)\n",
        "\n",
        "    # Define the pattern to remove the footer and everything that follows\n",
        "    footer_start = \"Back to top\"\n",
        "    if footer_start in md_content:\n",
        "        md_content = md_content.split(footer_start)[0]\n",
        "\n",
        "    # Remove patterns like \"---|---\" and \"---|---|---|---\"\n",
        "    md_content = re.sub(r'---(\\|---)+', '\\n', md_content)\n",
        "\n",
        "    # Replace the character `|` with an empty newline\n",
        "    md_content = md_content.replace('|', '\\n')\n",
        "\n",
        "    # Replace \"[__PDF]\" with \"[PDF]\"\n",
        "    md_content = md_content.replace('[__  PDF]', '[PDF]')\n",
        "\n",
        "    return md_content.strip()\n"
      ],
      "metadata": {
        "id": "rCIqiuAUHIfU"
      },
      "execution_count": 135,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# CanLII metadata extractor\n",
        "\n",
        "Should be the same across all CanLII cases. Doesn't contain much information."
      ],
      "metadata": {
        "id": "8opW5jQm_acI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def capture_canlii_metadata(md_content: str) -> Dict[str, str]:\n",
        "    \"\"\"\n",
        "    Captures specific metadata (date, file number, citation) from markdown content.\n",
        "\n",
        "    Args:\n",
        "        md_content (str): The input markdown content.\n",
        "\n",
        "    Returns:\n",
        "        Dict[str, str]: A dictionary containing captured metadata.\n",
        "    \"\"\"\n",
        "\n",
        "    metadata = {}\n",
        "\n",
        "    # Capture date\n",
        "    date_match = re.search(r'Date: (\\d{4}-\\d{2}-\\d{2})', md_content)\n",
        "    if date_match:\n",
        "        metadata['date'] = date_match.group(1)\n",
        "\n",
        "    # Capture file number\n",
        "    file_match = re.search(r'File number: ([A-Z0-9]+)', md_content)\n",
        "    if file_match:\n",
        "        metadata['file_number'] = file_match.group(1)\n",
        "\n",
        "    # Capture citation\n",
        "    citation_pattern = r'Citation: (.+?)<<(.+?)>>, retrieved\\s+on\\s+(\\d{4}-\\d{2}-\\d{2})'\n",
        "    citation_match = re.search(citation_pattern, md_content, re.DOTALL)\n",
        "    if citation_match:\n",
        "        metadata['citation'] = f\"{citation_match.group(1).strip()} {citation_match.group(2)} retrieved on {citation_match.group(3)}\"\n",
        "\n",
        "    return metadata\n"
      ],
      "metadata": {
        "id": "RtQxzHFyOhsF"
      },
      "execution_count": 119,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "2RSMxfSGkWG9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def convert_to_standard_date(date_string: str) -> str:\n",
        "    \"\"\"\n",
        "    Converts a date string to a standard format YYYY-MM-DD.\n",
        "\n",
        "    Args:\n",
        "        date_string (str): Input date string.\n",
        "\n",
        "    Returns:\n",
        "        str: Date in standard format.\n",
        "    \"\"\"\n",
        "    # Define the expected date formats for the input strings\n",
        "    date_formats = [\"%Y-%m-%d\", \"%B %d, %Y\"]\n",
        "\n",
        "    for date_format in date_formats:\n",
        "        try:\n",
        "            # Parse the string into a datetime object\n",
        "            date_obj = datetime.strptime(date_string, date_format)\n",
        "            # Return the formatted string\n",
        "            return date_obj.strftime(\"%Y-%m-%d\")\n",
        "        except ValueError:\n",
        "            pass\n",
        "\n",
        "    # If all parsing attempts fail, return the original string\n",
        "    return date_string\n",
        "\n",
        "\n",
        "def extract_metadata(pattern: str, md_content: str, known_patterns: list) -> list:\n",
        "    \"\"\"\n",
        "    Extract metadata using the provided pattern from md_content.\n",
        "\n",
        "    Args:\n",
        "    - pattern: The regex pattern to search for.\n",
        "    - md_content: The content to search within.\n",
        "    - known_patterns: Known metadata patterns to consider in lookahead.\n",
        "\n",
        "    Returns:\n",
        "    - A list of names found based on the pattern.\n",
        "    \"\"\"\n",
        "    match = re.search(pattern, md_content, re.DOTALL | re.IGNORECASE)\n",
        "    if match:\n",
        "        cleaned_string = re.sub(r'\\n+', ' ', match.group(1)).strip()\n",
        "        names_list = [name for name in cleaned_string.split('  ') if name]\n",
        "        return names_list\n",
        "    return []\n",
        "\n",
        "def extract_parties(md_content: str) -> list:\n",
        "    \"\"\"\n",
        "    Extract parties from md_content.\n",
        "\n",
        "    Args:\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    role_pattern = re.compile('|'.join(map(re.escape, ROLES)), re.IGNORECASE)\n",
        "\n",
        "    match = re.search(SKCA_2015_METADATA_PATTERNS['between'], md_content, re.DOTALL)\n",
        "\n",
        "    if match:\n",
        "        between_values = [line.strip() for line in match.group(1).strip().split('\\n')\n",
        "                        if line.strip() and line.strip().lower() != 'and']\n",
        "\n",
        "        parties_list = []\n",
        "        prev_party = None\n",
        "        current_role = \"\"\n",
        "        for line in between_values:\n",
        "            if role_pattern.search(line):  # Using regex search here\n",
        "                if current_role:\n",
        "                    current_role += \" \" + line\n",
        "                else:\n",
        "                    current_role = line\n",
        "            else:\n",
        "                if prev_party and current_role:\n",
        "                    parties_list.append({'party': prev_party, 'role': current_role})\n",
        "                    current_role = \"\"\n",
        "                prev_party = line\n",
        "\n",
        "        # Handle the last party-role pair\n",
        "        if prev_party and current_role:\n",
        "            parties_list.append({'party': prev_party, 'role': current_role})\n",
        "\n",
        "        return parties_list\n",
        "\n",
        "def extract_counsel(md_content: str) -> list:\n",
        "    \"\"\"\n",
        "    Extract counsel from md_content.\n",
        "\n",
        "    Args:\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    # Extracting counsel as a special case:\n",
        "    counsel_pattern = (\n",
        "        r'(?:'                   # Non-capturing group start\n",
        "        r'[\\w\\s-]+'              # Matches word characters, spaces, and hyphens\n",
        "        r'(?:, [KQ].C.)?'        # Optionally matches ', K.C.' or ', Q.C.'\n",
        "        r' and '                 # Matches ' and '\n",
        "        r')?'                    # End of non-capturing group, which is optional\n",
        "        r'[\\w\\s-]+'              # Matches word characters, spaces, and hyphens again\n",
        "        r'(?:, [KQ].C.)?'        # Optionally matches ', K.C.' or ', Q.C.' again\n",
        "        r',?'                    # Optional comma\n",
        "        r' for the '             # Matches ' for the '\n",
        "        r'[\\w\\s\\-A-Za-z]+'       # Matches word characters, spaces, hyphens, and English letters\n",
        "    )\n",
        "\n",
        "    counsel_string = re.findall(counsel_pattern, md_content)\n",
        "\n",
        "    # Remove whitespace\n",
        "    cleaned_counsel = re.sub(r'\\n', '', counsel_string[0])\n",
        "    cleaned_counsel = re.sub(r' +', ' ', cleaned_counsel)\n",
        "    cleaned_counsel = cleaned_counsel.strip()\n",
        "\n",
        "    # Placeholder for our final, cleaned-up information\n",
        "    good_information = \"\"\n",
        "\n",
        "    while True:\n",
        "        match = re.search(r'(.*?)(for the \\w+)', cleaned_counsel)\n",
        "        if match:\n",
        "            # Add the matched segment to our good information\n",
        "            good_information += match.group(1) + match.group(2) + \" \"\n",
        "            # Remove the processed segment from cleaned_counsel\n",
        "            cleaned_counsel = cleaned_counsel.replace(match.group(0), '', 1)\n",
        "        else:\n",
        "            break\n",
        "\n",
        "    # Optionally, trim any trailing spaces\n",
        "    good_information = good_information.strip()\n",
        "\n",
        "    # Find all occurrences of 'for the [word]' and split the string based on them\n",
        "    roles = re.findall(r'for the \\w+', good_information)\n",
        "    segments = re.split(r'for the \\w+', good_information)\n",
        "\n",
        "    final_list = []\n",
        "    for role, segment in zip(roles, segments):\n",
        "        # Updated regex split logic\n",
        "        names = [name.strip() for name in re.split(r',? and |,(?![\\s]?[KQ]\\.C\\.)', segment)]\n",
        "        for name in names:\n",
        "            if name:  # Ensure we don't append empty names\n",
        "                final_list.append(name + ' ' + role)\n",
        "\n",
        "    return final_list\n",
        "\n",
        "\n",
        "def capture_skca_metadata(md_content: str) -> Dict[str, Union[str, List[str]]]:\n",
        "    \"\"\"\n",
        "    Captures specific secondary metadata from markdown content.\n",
        "\n",
        "    Args:\n",
        "        md_content (str): The input markdown content.\n",
        "\n",
        "    Returns:\n",
        "        Dict[str, Union[str, List[str]]]: A dictionary containing captured metadata.\n",
        "    \"\"\"\n",
        "    metadata = {}\n",
        "    metadata_patterns = SKCA_2015_METADATA_PATTERNS\n",
        "\n",
        "    # Extracting special case lists\n",
        "    for key, pattern in metadata_patterns.items():\n",
        "        match = re.search(\n",
        "            pattern,\n",
        "            md_content,\n",
        "            re.DOTALL | re.IGNORECASE\n",
        "        )\n",
        "        try:\n",
        "            if match:\n",
        "                metadata[key] = ' '.join(match.group(1).split()).strip()\n",
        "                print(metadata[key] + \"\\n\")\n",
        "        except IndexError:\n",
        "            pass\n",
        "\n",
        "    metadata['between'] = extract_parties(md_content)\n",
        "    metadata['counsel'] = extract_counsel(md_content)\n",
        "\n",
        "    # Extract the date components and convert to standard format\n",
        "    if 'application_heard' in metadata:\n",
        "        metadata['application_heard'] = ' '.join(metadata['application_heard'].split()[:3])\n",
        "        metadata['application_heard'] = convert_to_standard_date(metadata['application_heard'])\n",
        "\n",
        "    if 'appeal_heard' in metadata:\n",
        "        metadata['appeal_heard'] = convert_to_standard_date(metadata['appeal_heard'])\n",
        "\n",
        "    metadata['date_secondary'] = convert_to_standard_date(metadata['date_secondary'])\n",
        "\n",
        "    # Testing for multiple judge detection\n",
        "\n",
        "    known_patterns = [\n",
        "        r'Docket:',\n",
        "        r'Citation:',\n",
        "        r'Date:',\n",
        "        r'Between:',\n",
        "        r'Before:',\n",
        "        r'Disposition:',\n",
        "        r'Written reasons by:',\n",
        "        r'In concurrence:',\n",
        "        r'In dissent:',\n",
        "        r'On Application From:',\n",
        "        r'Application Heard:'\n",
        "        r'On appeal from:',\n",
        "        r'Appeal heard:',\n",
        "        r'Counsel:',\n",
        "    ]\n",
        "\n",
        "    # Patterns to check\n",
        "    patterns_to_check = {\n",
        "        'written_reasons_by': r'Written reasons by:\\s*(.+?)(?=\\s{2,}(?:' + '|'.join(known_patterns) + r')|$)',\n",
        "        'in_concurrence': r'In concurrence:\\s*(.+?)(?=\\s{2,}(?:' + '|'.join(known_patterns) + r')|$)',\n",
        "        'in_dissent': r'In dissent:\\s*(.+?)(?=\\s{2,}(?:' + '|'.join(known_patterns) + r')|$)'\n",
        "    }\n",
        "\n",
        "    # Iterate over each pattern, extracting the metadata and storing in the 'metadata' dictionary\n",
        "    for key, pattern in patterns_to_check.items():\n",
        "        metadata[key] = extract_metadata(pattern, md_content, known_patterns)\n",
        "\n",
        "    return metadata\n"
      ],
      "metadata": {
        "id": "sCMXJoy9cnH4"
      },
      "execution_count": 202,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_paragraphs(md_content):\n",
        "    # Split the content using the '--' pattern\n",
        "    paragraphs = md_content.split('\\n__\\n')\n",
        "\n",
        "    # Strip leading and trailing whitespace from each paragraph\n",
        "    paragraphs = [p.strip() for p in paragraphs if p.strip()]\n",
        "\n",
        "    return paragraphs\n"
      ],
      "metadata": {
        "id": "PdQtiqFG9v7I"
      },
      "execution_count": 121,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    html_filepath = \"2018skca92.html\"\n",
        "    markdown_filepath = \"2018skca92.md\"\n",
        "\n",
        "    with open(html_filepath, 'r', encoding='utf-8') as file:\n",
        "        html_content = file.read()\n",
        "\n",
        "    markdown_content = html_to_markdown(html_content)\n",
        "    refined_markdown_content = refine_markdown(markdown_content)\n",
        "    paragraphs = extract_paragraphs(refined_markdown_content)\n",
        "    canlii_metadata = capture_canlii_metadata(paragraphs[0])\n",
        "    skca_metadata = capture_skca_metadata(paragraphs[0])\n",
        "\n",
        "    with open(markdown_filepath, 'w', encoding='utf-8') as file:\n",
        "        file.write(refined_markdown_content)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E60B5xHv53NO",
        "outputId": "2295861a-bff6-45d2-a9e5-680cc787ebf5"
      },
      "execution_count": 203,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CACV3156\n",
            "\n",
            "Hilmoe v Hilmoe, 2018 SKCA 92 (CanLII), <<https://canlii.ca/t/hw8fs>>, retrieved on 2023-10-07\n",
            "\n",
            "2018-11-23\n",
            "\n",
            "Michael Hilmoe and Gaylynn Reimer Appellants (Respondents) And Dianne Hilmoe Respondent (Applicant)\n",
            "\n",
            "Appeal dismissed\n",
            "\n",
            "[2017 SKQB 312](/en/sk/skqb/doc/2017/2017skqb312/2017skqb312.html), Swift Current\n",
            "\n",
            "June 13, 2018\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for key, value in skca_metadata.items():\n",
        "    print(key + \": \", value)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7gxCtDxH93Bv",
        "outputId": "3b4c91cc-b858-4fa7-fb93-67f70535b378"
      },
      "execution_count": 205,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "docket:  CACV3156\n",
            "citation_secondary:  Hilmoe v Hilmoe, 2018 SKCA 92 (CanLII), <<https://canlii.ca/t/hw8fs>>, retrieved on 2023-10-07\n",
            "date_secondary:  2018-11-23\n",
            "between:  [{'party': 'Michael Hilmoe and Gaylynn Reimer', 'role': 'Appellants (Respondents)'}, {'party': 'Dianne Hilmoe', 'role': 'Respondent (Applicant)'}]\n",
            "disposition:  Appeal dismissed\n",
            "on_appeal_from:  [2017 SKQB 312](/en/sk/skqb/doc/2017/2017skqb312/2017skqb312.html), Swift Current\n",
            "appeal_heard:  2018-06-13\n",
            "counsel:  ['Kuski Bassett for the Appellants']\n",
            "written_reasons_by:  ['The Honourable Mr. Justice Herauf and', '** ** The Honourable Madam Justice Schwann', 'In Dissent The Honourable Mr. Justice Ottenbreit', 'On Appeal From: [2017 SKQB 312](/en/sk/skqb/doc/2017/2017skqb312/2017skqb312.html), Swift Current']\n",
            "in_concurrence:  []\n",
            "in_dissent:  []\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(paragraphs[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "81jExQB9bEOf",
        "outputId": "c64655ac-d361-43ed-919f-da44df49d567"
      },
      "execution_count": 174,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Home](/en/) â€º [Saskatchewan](/en/sk/) â€º [Court of Appeal for\n",
            "Saskatchewan](/en/sk/skca/) â€º 2018 SKCA 92 (CanLII)\n",
            "\n",
            "\n",
            "\n",
            "# Hilmoe v Hilmoe, 2018 SKCA 92 (CanLII)\n",
            "\n",
            "  \n",
            "  \n",
            "  \n",
            "   \n",
            "  \n",
            "\n",
            "[PDF](/en/sk/skca/doc/2018/2018skca92/2018skca92.pdf)\n",
            "\n",
            "Date: 2018-11-23\n",
            "\n",
            "File number: CACV3156\n",
            "\n",
            "Other citations:\n",
            "\n",
            "300 ACWS (3d) 204 -- [2019] 1 WWR 118 -- 16 RFL (8th) 288 -- 42 ETR (4th) 29\n",
            "-- 96 RPR (5th) 12\n",
            "\n",
            "Citation: Hilmoe v Hilmoe, 2018 SKCA 92 (CanLII), <<https://canlii.ca/t/hw8fs>>,\n",
            "retrieved on 2023-10-07\n",
            "\n",
            "    \n",
            "\n",
            "\n",
            "\n",
            "Court of Appeal for Saskatchewan\n",
            "\n",
            "Docket: CACV3156\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Citation: _Hilmoe v Hilmoe_ , 2018 SKCA 92  \n",
            "  \n",
            "\n",
            "  \n",
            "  \n",
            "Date: 2018-11-23  \n",
            "  \n",
            "Between:  \n",
            "  \n",
            "Michael Hilmoe and Gaylynn Reimer  \n",
            "  \n",
            "Appellants  \n",
            "(Respondents)  \n",
            "  \n",
            "And  \n",
            "  \n",
            "Dianne Hilmoe  \n",
            "  \n",
            "Respondent  \n",
            "(Applicant)  \n",
            "  \n",
            "  \n",
            "  \n",
            "Before:\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Ottenbreit, Herauf and Schwann JJ.A.  \n",
            "  \n",
            "Disposition:\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Appeal dismissed  \n",
            "  \n",
            "Written reasons by:\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "The Honourable Mr. Justice Herauf and  \n",
            "  \n",
            "** **\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "The Honourable Madam Justice Schwann  \n",
            "  \n",
            "In Dissent\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "The Honourable Mr. Justice Ottenbreit  \n",
            "  \n",
            "On Appeal From:\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "[2017 SKQB 312](/en/sk/skqb/doc/2017/2017skqb312/2017skqb312.html), Swift\n",
            "Current  \n",
            "  \n",
            "Appeal Heard:\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "June 13, 2018  \n",
            "  \n",
            "Counsel:\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Holli A. Kuski Bassett for the Appellants  \n",
            "  \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Jason M. Clayards for the Respondent  \n",
            "  \n",
            "\n",
            "  \n",
            "  \n",
            "  \n",
            "\n",
            "\n",
            "  \n",
            "\n",
            "Herauf and Schwann JJ.A.\n",
            "\n",
            "# I.                  Introduction\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "def extract_counsel(counsel_string: str) -> list:\n",
        "    counsel_list = []\n",
        "\n",
        "    # 1. Self-representation: Using non-capturing group\n",
        "    self_rep_pattern = r'[\\w\\s-]+ on (?:his|her) own behalf'\n",
        "    self_rep_matches = re.findall(self_rep_pattern, counsel_string)\n",
        "    counsel_list.extend(self_rep_matches)  # directly append matched strings\n",
        "\n",
        "    # 2. Names followed by \", K.C.\" or \", Q.C.\"\n",
        "    kc_qc_pattern = r'[\\w\\s-]+, [KQ]\\.C\\.'\n",
        "    kc_qc_matches = re.findall(kc_qc_pattern, counsel_string)\n",
        "    counsel_list.extend(kc_qc_matches)\n",
        "\n",
        "    # 3. Names with \"for the [role]\"\n",
        "    role_pattern = r'[\\w\\s-]+(?= for the [\\w\\s\\-\\'A-Za-z]+) for the [\\w\\s\\-\\'A-Za-z]+'\n",
        "    role_matches = re.findall(role_pattern, counsel_string)\n",
        "    counsel_list.extend(role_matches)\n",
        "\n",
        "    return counsel_list\n",
        "\n",
        "# Test\n",
        "test_string = \"\"\"\n",
        "Counsel:\n",
        "\n",
        "Michael Taylor on his own behalf\n",
        "Wade McBride, K.C., and Carlene Ready for the Respondent\n",
        "Lisa Watson for Saskatchewan Lawyers' Insurance Association Inc.\n",
        "\"\"\"\n",
        "\n",
        "print(extract_counsel(test_string))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "llS8Nzdx8gHK",
        "outputId": "51fc2e6d-123a-4c09-94d0-cd4d2736c80c"
      },
      "execution_count": 125,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['\\n\\nMichael Taylor on his own behalf', '\\n\\nMichael Taylor on his own behalf  \\nWade McBride, K.C.', \" and Carlene Ready for the Respondent  \\nLisa Watson for Saskatchewan Lawyers' Insurance Association Inc\"]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_markdown(filename):\n",
        "    with open(filename, 'r') as file:\n",
        "        lines = file.readlines()\n",
        "\n",
        "    cleaned_lines = []\n",
        "    for line in lines:\n",
        "        # Strip whitespace from each line\n",
        "        line = line.strip()\n",
        "\n",
        "        # Skip lines with only whitespace\n",
        "        if not line:\n",
        "            continue\n",
        "\n",
        "        # Remove the underscore formatting\n",
        "        line = line.replace(\"_\", \"\")\n",
        "\n",
        "        # If there's a desire to process links differently in the future, this is where you'd do it.\n",
        "        # For now, we'll leave links intact.\n",
        "\n",
        "        cleaned_lines.append(line)\n",
        "\n",
        "    return '\\n'.join(cleaned_lines)\n",
        "\n",
        "\n",
        "# Name of the file you want to process\n",
        "filename = \"2018skca89.md\"\n",
        "cleaned_content = clean_markdown(filename)\n",
        "\n",
        "# Optionally save the cleaned content to a new file\n",
        "with open(\"cleaned_\" + filename, 'w') as file:\n",
        "    file.write(cleaned_content)\n",
        "\n"
      ],
      "metadata": {
        "id": "D5X0i2Z_iB16"
      },
      "execution_count": 126,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "text = paragraphs[0]\n",
        "\n",
        "BASE_ROLES = [\n",
        "    'plaintiff', 'plaintiffs',\n",
        "    'respondent', 'respondents',\n",
        "    'appellant', 'appellants',\n",
        "    'applicant', 'applicants'\n",
        "]\n",
        "\n",
        "# Generate combinations with brackets and slashes\n",
        "ROLES = BASE_ROLES + [\n",
        "    f\"({role})\" for role in BASE_ROLES\n",
        "] + [\n",
        "    f\"{role1}/{role2}\" for role1 in BASE_ROLES for role2 in BASE_ROLES\n",
        "]\n",
        "\n",
        "role_pattern = re.compile('|'.join(map(re.escape, ROLES)), re.IGNORECASE)\n",
        "\n",
        "between_match = re.search(SKCA_2015_METADATA_PATTERNS['between'], text, re.DOTALL)\n",
        "\n",
        "if between_match:\n",
        "    between_values = [line.strip() for line in between_match.group(1).strip().split('\\n')\n",
        "                      if line.strip() and line.strip().lower() != 'and']\n",
        "\n",
        "    parties_list = []\n",
        "    prev_party = None\n",
        "    current_role = \"\"\n",
        "    for line in between_values:\n",
        "        if role_pattern.search(line):  # Using regex search here\n",
        "            if current_role:\n",
        "                current_role += \" \" + line\n",
        "            else:\n",
        "                current_role = line\n",
        "        else:\n",
        "            if prev_party and current_role:\n",
        "                parties_list.append({'party': prev_party, 'role': current_role})\n",
        "                current_role = \"\"\n",
        "            prev_party = line\n",
        "\n",
        "    # Handle the last party-role pair\n",
        "    if prev_party and current_role:\n",
        "        parties_list.append({'party': prev_party, 'role': current_role})\n",
        "\n",
        "    print(parties_list)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Woef2Thlfo9a",
        "outputId": "b75bb01e-241b-44fe-ad7e-c8cd23fa4941"
      },
      "execution_count": 180,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[{'party': 'Allan Gordon Bouvier', 'role': 'Applicant/Appellant'}, {'party': 'Her Majesty the Queen', 'role': 'Respondent/Respondent'}]\n"
          ]
        }
      ]
    }
  ]
}